{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcf8ce99",
   "metadata": {},
   "source": [
    "# Atmospheric Model Intercomparison Project (AMIP) Validation\n",
    "\n",
    "To investigate global stilling, we want to force the models realistic historical SST forcing in order to force the models with the observed realization. To do this we use the `amip-hist` model runs.\n",
    "\n",
    "__Variables analyzed__\n",
    "- `uas`: eastward wind component (usually 10 m) [$m \\ s^{-1}$]\n",
    "- `vas`: northward wind component (usually 10 m) [$m \\ s^{-1}$]\n",
    "- `nsws`: artificially constructed variable for net windspeed $\\sqrt{uas^2 + vas^2}$\n",
    "\n",
    "11 models are available on Andromeda (The BC Cluster) at `/data/projects/bccg/CMIP6/amip-hist/mon/uas` and `/data/projects/bccg/CMIP6/amip-hist/mon/vas` respectively. Models are at _monthly_ resolution and aggregated _yearly_ before any trend analysis is analyzed.\n",
    "\n",
    "__Steps to connect to BC Cluster__\n",
    "1. Install Remote SSH and Remote X11 extensions in VScode\n",
    "2. `ssh -Y username@andromeda.bc.edu`\n",
    "3. Enter password\n",
    "4. `cd ~/mmfs1/data/valencig/winds-of-change`\n",
    "<!-- 5. `module load python/3.9.0` $\\leftarrow$ add to .tcshrc file -->\n",
    "\n",
    "__Getting Conda up and Running__\n",
    "1. `module load anaconda/2023.07-p3.11`\n",
    "2. `conda init tcsh`\n",
    "3. `conda create -n _envname_ python=3.11`\n",
    "4. `conda activate _envname_`\n",
    "\n",
    "This will create a conda environment in the `/mmfs1/data/_username_/.conda/envs/_envname_` directory. To automatically use this environment on login use add `conda activate _envname_` to your `.tcshrc` file.\n",
    "\n",
    "__For a faster environment solver__\n",
    "1. `conda install -n _envname_ conda-libmamba-solver`\n",
    "2. `conda config --set solver libmamba`\n",
    "\n",
    "__Export Environment__: `conda env export > environment.yml`\n",
    "\n",
    "__Note__: To use `matplotlib` we must install $\\LaTeX$. Jupyter Notebooks use MathJax under the hood which is why we only need to install if it using $\\LaTeX$ in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ce0c44c-9012-4577-8a14-b27825e7e965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.mpl.ticker import LatitudeFormatter, LongitudeFormatter\n",
    "import nc_time_axis\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import cf_xarray as cfxr\n",
    "import regionmask\n",
    "from glob import glob\n",
    "import os\n",
    "# Cannot use scienceplots because of latex issue on BC cluster\n",
    "# import scienceplots\n",
    "# plt.style.use([\"science\", \"nature\"])\n",
    "%matplotlib inline\n",
    "\n",
    "xr.set_options(keep_attrs=True)\n",
    "%load_ext rich\n",
    "from rich import print  # pretty printing\n",
    "from tqdm import tqdm  # progress bar\n",
    "\n",
    "# from importlib import reload\n",
    "\n",
    "# Playing nice with CMIP6\n",
    "# from xmip.preprocessing import combined_preprocessing\n",
    "from xclim.ensembles import create_ensemble, ensemble_mean_std_max_min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5578d69f-bfaf-48d9-b58b-4f2516fd3f19",
   "metadata": {},
   "source": [
    "## CMIP vs AMIP\n",
    "- Using AMIP models (prescribed SSTs) to check against observational data\n",
    "- Observation is only realization of the state, so use the prescribed SST to capture that single state.\n",
    "- Pull in 7 amip-hist datasets, download and analyze\n",
    "- Model is fundamentally flawed if AMIP doesn't capture multi-decadal trend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40943d86",
   "metadata": {},
   "source": [
    "## Create the ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8938594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">All models:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "All models:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'IPSL-CM6A-LR'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'IITM-ESM'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'CanESM5'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'CNRM-CM6-1-HR'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'FGOALS-f3-L'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'CAMS-CSM1-0'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'BCC-CSM2-MR'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'CNRM-CM6-1'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'MIROC6'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'CNRM-ESM2-1'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'MRI-ESM2-0'</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[32m'IPSL-CM6A-LR'\u001b[0m,\n",
       "    \u001b[32m'IITM-ESM'\u001b[0m,\n",
       "    \u001b[32m'CanESM5'\u001b[0m,\n",
       "    \u001b[32m'CNRM-CM6-1-HR'\u001b[0m,\n",
       "    \u001b[32m'FGOALS-f3-L'\u001b[0m,\n",
       "    \u001b[32m'CAMS-CSM1-0'\u001b[0m,\n",
       "    \u001b[32m'BCC-CSM2-MR'\u001b[0m,\n",
       "    \u001b[32m'CNRM-CM6-1'\u001b[0m,\n",
       "    \u001b[32m'MIROC6'\u001b[0m,\n",
       "    \u001b[32m'CNRM-ESM2-1'\u001b[0m,\n",
       "    \u001b[32m'MRI-ESM2-0'\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading models: 100%|██████████| 11/11 [00:20<00:00,  1.88s/it]\n"
     ]
    }
   ],
   "source": [
    "# Get all model names\n",
    "model_folders = glob('/data/projects/bccg/CMIP6/amip-hist/mon/vas/*')\n",
    "model_names = [f.split('/')[-1] for f in model_folders]\n",
    "print('All models:')\n",
    "print(model_names)\n",
    "# Create dictionary for models and their realizations\n",
    "dset_dict = dict()\n",
    "for model in tqdm(model_names, desc='Loading models'):\n",
    "    # Paths for u and v wind components\n",
    "    # Sort to make realization indices increasing\n",
    "    model_uas = sorted(glob(f'/data/projects/bccg/CMIP6/amip-hist/mon/uas/{model}/*'))\n",
    "    model_vas = sorted(glob(f'/data/projects/bccg/CMIP6/amip-hist/mon/vas/{model}/*'))\n",
    "    # Get realization nunmbers\n",
    "    uas_realizations = [f.split('_')[-3] for f in model_uas]\n",
    "    vas_realizations = [f.split('_')[-3] for f in model_uas]\n",
    "    # Create ensembles\n",
    "    uas_ens = create_ensemble(model_uas, realizations=uas_realizations)\n",
    "    vas_ens = create_ensemble(model_vas, realizations=vas_realizations)\n",
    "    # Combine realizations\n",
    "    model_ens = xr.merge([uas_ens, vas_ens])\n",
    "    # Create new dimension for NSWS\n",
    "    model_ens['nsws'] = (model_ens.uas**2 + model_ens.vas**2)**0.5\n",
    "    model_ens['nsws'] = model_ens.nsws.assign_attrs(\n",
    "        standard_name='near_surface_wind',\n",
    "        description='Net Near-Surface Wind Speed',\n",
    "        long_name='Net Near-Surface Wind Speed'\n",
    "    )\n",
    "    # Add model\n",
    "    dset_dict[model] = model_ens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29563edd",
   "metadata": {},
   "source": [
    "## Land vs. Ocean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c4712b1-a5c0-491b-8086-0c07638e63cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Plotting models:   0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "keys = model_names\n",
    "n_models = len(keys)\n",
    "land_region = regionmask.defined_regions.natural_earth_v5_0_0.land_110  # Land has value 0\n",
    "\n",
    "fig = plt.figure(figsize=(14, int(n_models*3)), constrained_layout=True)\n",
    "gs = fig.add_gridspec(n_models, 2, width_ratios=[3, 1])\n",
    "\n",
    "for i, k in enumerate(tqdm(keys, desc='Plotting models')):\n",
    "    # Name of model\n",
    "    # name = k.split('.')[2]\n",
    "    name=k\n",
    "    # map axis\n",
    "    map = fig.add_subplot(gs[i, 0], projection=ccrs.Mollweide())\n",
    "    # timeseries axis\n",
    "    ts = fig.add_subplot(gs[i, 1])\n",
    "    # Get member\n",
    "    ds = dset_dict[k]  # rename to work with xclim ensembles\n",
    "    ds = ds.cf.sel(T=slice('1978', None))  # 1978-2014\n",
    "    # Reduce the dataset\n",
    "    da = ensemble_mean_std_max_min(ds)\n",
    "    # Extract eastward wind\n",
    "    sfcWind = da['nsws_mean']\n",
    "    # Plot map\n",
    "    trend = (\n",
    "        sfcWind.cf.groupby('T.year').mean()\n",
    "        .polyfit('year', deg=1, skipna=True)\n",
    "        .polyfit_coefficients.sel(degree=1)*10  # decadal\n",
    "    )\n",
    "    im = trend.plot(ax=map, vmin=-0.2, vmax=0.2, cmap='coolwarm', transform=ccrs.PlateCarree(), add_colorbar=False)\n",
    "    cb = plt.colorbar(im, orientation=\"vertical\", pad=0.15)\n",
    "    cb.set_label(label='Decadal Trend [m/s]')\n",
    "    # Mask data\n",
    "    land_mask = land_region.mask(sfcWind.cf['X'], sfcWind.cf['Y'])\n",
    "    land = sfcWind.where(land_mask == 0)\n",
    "    ocean = sfcWind.where(land_mask != 0)\n",
    "    # Plot time series (normalize data to compare)\n",
    "    l_ts = land.cf.resample(T='1Y').mean().mean(['lat','lon'])\n",
    "    ((l_ts-l_ts.min())/(l_ts.max()-l_ts.min())).plot(label='land')\n",
    "    o_ts = ocean.cf.resample(T='1Y').mean().mean(['lat','lon'])\n",
    "    ((o_ts-o_ts.min())/(o_ts.max()-o_ts.min())).plot(label='ocean')\n",
    "    # Map plot options\n",
    "    map.coastlines()\n",
    "    map.set_title(name)\n",
    "    # Time series plot options\n",
    "    ts.set_title(name)\n",
    "    ts.set_xlabel('')\n",
    "    ts.legend(loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xcdat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
